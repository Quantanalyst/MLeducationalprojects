## Regularization 

In machine learning, **regularization** is the process of adding information in order to prevent **overfitting**. Regularization can be described as a form of regression, that constrains/ regularizes or shrinks the coefficient estimates towards zero. In other words, this technique discourages learning a more complex or flexible model to avoid the risk of overfitting.

Regularization applies to loss functions. 










P.S. Another way of avoiding overfitting is using cross validation, that helps in estimating the error over test set, and in deciding what parameters work best for your model.
